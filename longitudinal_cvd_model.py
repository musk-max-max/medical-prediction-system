#!/usr/bin/env python3
"""
å¼—é›·æ˜æ±‰çºµå‘å¿ƒè¡€ç®¡ç–¾ç—…é£é™©é¢„æµ‹æ¨¡å‹
ä¸“é—¨å¤„ç†æ¯ä¸ªæ‚£è€…çš„å¤šæ¬¡ä½“æ£€æ•°æ®ï¼Œè¿›è¡Œæ—¶é—´åºåˆ—åˆ†æå’Œç”Ÿå­˜åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import joblib
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œéšæœºç§å­
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
np.random.seed(42)

class LongitudinalFraminghamPredictor:
    """å¼—é›·æ˜æ±‰çºµå‘å¿ƒè¡€ç®¡ç–¾ç—…é£é™©é¢„æµ‹å™¨"""
    
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.imputer = SimpleImputer(strategy='median')
        self.feature_names = []
        
    def load_and_analyze_data(self, file_path):
        """åŠ è½½å’Œåˆ†æçºµå‘æ•°æ®"""
        print("ğŸ” åŠ è½½å¼—é›·æ˜æ±‰çºµå‘å¿ƒè„ç ”ç©¶æ•°æ®...")
        df = pd.read_csv(file_path)
        
        print(f"æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(f"  æ€»è®°å½•æ•°: {len(df)}")
        print(f"  ç‹¬ç‰¹æ‚£è€…æ•°: {df['RANDID'].nunique()}")
        print(f"  ä½“æ£€æ¬¡æ•°åˆ†å¸ƒ:")
        visit_counts = df.groupby('RANDID').size()
        for visits, count in visit_counts.value_counts().sort_index().items():
            print(f"    {visits}æ¬¡ä½“æ£€: {count}äºº")
        
        print(f"  CVDæ€»æ‚£ç—…ç‡: {(df['CVD']==1).mean():.3f}")
        
        return df
    
    def create_modeling_approaches(self, df):
        """åˆ›å»ºä¸åŒçš„å»ºæ¨¡æ–¹æ³•"""
        approaches = {}
        
        # æ–¹æ³•1: ä½¿ç”¨ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®é¢„æµ‹æœªæ¥CVDé£é™©
        print("\nğŸ“Š æ–¹æ³•1: åŸºçº¿é¢„æµ‹æ¨¡å‹ (ä½¿ç”¨ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®)")
        baseline_data = df[df['PERIOD'] == 1].copy()
        baseline_data['future_cvd'] = baseline_data['CVD']  # CVDè¡¨ç¤ºåœ¨ç ”ç©¶æœŸé—´æ˜¯å¦å‘ç”Ÿ
        approaches['baseline'] = self.prepare_baseline_features(baseline_data)
        
        # æ–¹æ³•2: ç”Ÿå­˜åˆ†ææ–¹æ³• - é¢„æµ‹CVDå‘ç”Ÿæ—¶é—´
        print("\nğŸ“Š æ–¹æ³•2: ç”Ÿå­˜åˆ†ææ¨¡å‹ (é¢„æµ‹CVDå‘ç”Ÿæ—¶é—´)")
        approaches['survival'] = self.prepare_survival_features(df)
        
        # æ–¹æ³•3: çºµå‘å˜åŒ–æ¨¡å‹ - åˆ©ç”¨å¤šæ¬¡ä½“æ£€çš„å˜åŒ–è¶‹åŠ¿
        print("\nğŸ“Š æ–¹æ³•3: çºµå‘å˜åŒ–æ¨¡å‹ (åˆ©ç”¨ä½“æ£€å˜åŒ–è¶‹åŠ¿)")
        approaches['longitudinal'] = self.prepare_longitudinal_features(df)
        
        return approaches
    
    def prepare_baseline_features(self, baseline_data):
        """å‡†å¤‡åŸºçº¿ç‰¹å¾(ç¬¬ä¸€æ¬¡ä½“æ£€)"""
        # é€‰æ‹©é‡è¦çš„å¿ƒè¡€ç®¡é£é™©å› ç´ 
        risk_factors = [
            'SEX', 'AGE', 'TOTCHOL', 'SYSBP', 'DIABP', 
            'CURSMOKE', 'CIGPDAY', 'BMI', 'DIABETES', 
            'BPMEDS', 'HEARTRTE', 'GLUCOSE', 'PREVCHD',
            'PREVAP', 'PREVMI', 'PREVSTRK', 'PREVHYP'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_features = [col for col in risk_factors if col in baseline_data.columns]
        
        # ç‰¹å¾å·¥ç¨‹
        df_features = baseline_data[available_features].copy()
        
        # åˆ›å»ºè¡ç”Ÿç‰¹å¾
        if 'SYSBP' in df_features.columns and 'DIABP' in df_features.columns:
            df_features['PULSE_PRESSURE'] = df_features['SYSBP'] - df_features['DIABP']
        
        if 'TOTCHOL' in df_features.columns and 'AGE' in df_features.columns:
            df_features['CHOL_AGE_RATIO'] = df_features['TOTCHOL'] / (df_features['AGE'] + 1)
        
        if 'BMI' in df_features.columns:
            df_features['BMI_CATEGORY'] = pd.cut(
                df_features['BMI'], 
                bins=[0, 18.5, 25, 30, float('inf')], 
                labels=[0, 1, 2, 3]
            ).astype(float)
        
        if 'CURSMOKE' in df_features.columns and 'CIGPDAY' in df_features.columns:
            df_features['SMOKING_RISK'] = (
                df_features['CURSMOKE'] * (1 + df_features['CIGPDAY'].fillna(0) / 20)
            )
        
        # å¹´é¾„ç›¸å…³é£é™©è¯„åˆ†
        if 'AGE' in df_features.columns and 'SEX' in df_features.columns:
            # ç”·æ€§å’Œå¥³æ€§çš„å¹´é¾„é£é™©ä¸åŒ
            df_features['AGE_SEX_RISK'] = df_features['AGE'] * (1.2 if df_features['SEX'].iloc[0] == 1 else 1.0)
        
        # ç›®æ ‡å˜é‡
        y = baseline_data['future_cvd']
        
        return {
            'X': df_features,
            'y': y,
            'description': 'åŸºçº¿é¢„æµ‹æ¨¡å‹ - ä½¿ç”¨ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®é¢„æµ‹æœªæ¥CVDé£é™©'
        }
    
    def prepare_survival_features(self, df):
        """å‡†å¤‡ç”Ÿå­˜åˆ†æç‰¹å¾"""
        # è·å–æ¯ä¸ªæ‚£è€…çš„ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®
        first_visits = df[df['PERIOD'] == 1].copy()
        
        # åˆ›å»ºç”Ÿå­˜åˆ†æç›®æ ‡å˜é‡
        # event: æ˜¯å¦å‘ç”ŸCVD (0=æœªå‘ç”Ÿ, 1=å‘ç”Ÿ)
        # time_to_event: è§‚å¯Ÿæ—¶é—´æˆ–äº‹ä»¶å‘ç”Ÿæ—¶é—´
        first_visits['event'] = first_visits['CVD']
        
        # å¯¹äºå‘ç”ŸCVDçš„æ‚£è€…ï¼Œä½¿ç”¨TIMECVDä½œä¸ºäº‹ä»¶æ—¶é—´
        # å¯¹äºæœªå‘ç”ŸCVDçš„æ‚£è€…ï¼Œä½¿ç”¨æœ€åä¸€æ¬¡ä½“æ£€æ—¶é—´ä½œä¸ºåˆ å¤±æ—¶é—´
        first_visits['time_to_event'] = first_visits['TIMECVD']
        
        # å¯¹äºæœªå‘ç”ŸCVDçš„æ‚£è€…ï¼Œè®¡ç®—æœ€åä¸€æ¬¡è§‚å¯Ÿæ—¶é—´
        max_time_per_patient = df.groupby('RANDID')['TIME'].max()
        no_cvd_mask = first_visits['CVD'] == 0
        first_visits.loc[no_cvd_mask, 'time_to_event'] = first_visits.loc[no_cvd_mask, 'RANDID'].map(max_time_per_patient)
        
        # è½¬æ¢ä¸ºå¹´ä¸ºå•ä½
        first_visits['time_to_event_years'] = first_visits['time_to_event'] / (24 * 365.25)
        
        # ç‰¹å¾é€‰æ‹©ï¼ˆç±»ä¼¼åŸºçº¿æ¨¡å‹ï¼‰
        risk_factors = [
            'SEX', 'AGE', 'TOTCHOL', 'SYSBP', 'DIABP', 
            'CURSMOKE', 'CIGPDAY', 'BMI', 'DIABETES', 
            'BPMEDS', 'HEARTRTE', 'GLUCOSE'
        ]
        
        available_features = [col for col in risk_factors if col in first_visits.columns]
        X = first_visits[available_features].copy()
        
        # æ·»åŠ ç‰¹å¾å·¥ç¨‹
        if 'SYSBP' in X.columns and 'DIABP' in X.columns:
            X['PULSE_PRESSURE'] = X['SYSBP'] - X['DIABP']
        
        return {
            'X': X,
            'y': first_visits['event'],
            'time': first_visits['time_to_event_years'],
            'description': 'ç”Ÿå­˜åˆ†ææ¨¡å‹ - é¢„æµ‹CVDå‘ç”Ÿæ—¶é—´å’Œæ¦‚ç‡'
        }
    
    def prepare_longitudinal_features(self, df):
        """å‡†å¤‡çºµå‘å˜åŒ–ç‰¹å¾"""
        # è®¡ç®—æ¯ä¸ªæ‚£è€…çš„å˜åŒ–è¶‹åŠ¿
        longitudinal_features = []
        
        # è·å–æœ‰å¤šæ¬¡ä½“æ£€çš„æ‚£è€…
        multi_visit_patients = df.groupby('RANDID').size()
        multi_visit_patients = multi_visit_patients[multi_visit_patients >= 2].index
        
        for patient_id in multi_visit_patients:
            patient_data = df[df['RANDID'] == patient_id].sort_values('PERIOD')
            
            if len(patient_data) < 2:
                continue
                
            # åŸºçº¿æ•°æ®ï¼ˆç¬¬ä¸€æ¬¡ä½“æ£€ï¼‰
            baseline = patient_data.iloc[0]
            
            # è®¡ç®—å…³é”®æŒ‡æ ‡çš„å˜åŒ–
            features = {'RANDID': patient_id}
            
            # åŸºçº¿ç‰¹å¾
            baseline_vars = ['SEX', 'AGE', 'DIABETES', 'PREVCHD', 'PREVMI', 'PREVSTRK']
            for var in baseline_vars:
                if var in baseline:
                    features[f'baseline_{var}'] = baseline[var]
            
            # è®¡ç®—å˜åŒ–è¶‹åŠ¿
            change_vars = ['TOTCHOL', 'SYSBP', 'DIABP', 'BMI', 'HEARTRTE', 'GLUCOSE']
            
            for var in change_vars:
                if var in patient_data.columns:
                    values = patient_data[var].dropna()
                    if len(values) >= 2:
                        # çº¿æ€§è¶‹åŠ¿
                        slope = np.polyfit(range(len(values)), values, 1)[0]
                        features[f'{var}_slope'] = slope
                        
                        # å˜åŒ–ç‡
                        first_val = values.iloc[0]
                        last_val = values.iloc[-1]
                        if first_val != 0:
                            features[f'{var}_change_rate'] = (last_val - first_val) / first_val
                        
                        # å˜å¼‚æ€§ï¼ˆæ ‡å‡†å·®ï¼‰
                        features[f'{var}_variability'] = values.std()
            
            # å¸çƒŸçŠ¶æ€å˜åŒ–
            if 'CURSMOKE' in patient_data.columns:
                smoke_values = patient_data['CURSMOKE'].dropna()
                if len(smoke_values) >= 2:
                    features['smoking_change'] = smoke_values.iloc[-1] - smoke_values.iloc[0]
            
            # ç”¨è¯çŠ¶æ€å˜åŒ–
            if 'BPMEDS' in patient_data.columns:
                med_values = patient_data['BPMEDS'].dropna()
                if len(med_values) >= 2:
                    features['medication_change'] = med_values.iloc[-1] - med_values.iloc[0]
            
            # ç›®æ ‡å˜é‡
            features['CVD'] = baseline['CVD']
            
            longitudinal_features.append(features)
        
        # è½¬æ¢ä¸ºDataFrame
        long_df = pd.DataFrame(longitudinal_features)
        
        if len(long_df) == 0:
            return None
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        feature_cols = [col for col in long_df.columns if col not in ['RANDID', 'CVD']]
        X = long_df[feature_cols]
        y = long_df['CVD']
        
        return {
            'X': X,
            'y': y,
            'description': 'çºµå‘å˜åŒ–æ¨¡å‹ - åˆ©ç”¨å¤šæ¬¡ä½“æ£€çš„å˜åŒ–è¶‹åŠ¿é¢„æµ‹CVDé£é™©'
        }
    
    def train_and_evaluate_approach(self, approach_name, approach_data):
        """è®­ç»ƒå’Œè¯„ä¼°ç‰¹å®šå»ºæ¨¡æ–¹æ³•"""
        if approach_data is None:
            print(f"âŒ {approach_name}: æ•°æ®å‡†å¤‡å¤±è´¥")
            return None
            
        print(f"\nğŸ¤– è®­ç»ƒ {approach_name}: {approach_data['description']}")
        
        X = approach_data['X']
        y = approach_data['y']
        
        print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}")
        print(f"æ ·æœ¬æ•°é‡: {X.shape[0]}")
        print(f"CVDæ‚£ç—…ç‡: {y.mean():.3f}")
        
        # å¤„ç†ç¼ºå¤±å€¼
        X_imputed = self.imputer.fit_transform(X)
        X_imputed = pd.DataFrame(X_imputed, columns=X.columns)
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X_imputed)
        X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),
            'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'Gradient_Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
        }
        
        results = {}
        
        for name, model in models.items():
            print(f"  è®­ç»ƒ {name}...")
            
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            # è¯„ä¼°æŒ‡æ ‡
            accuracy = accuracy_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_pred_proba)
            
            results[f"{approach_name}_{name}"] = {
                'model': model,
                'accuracy': accuracy,
                'auc': auc,
                'approach': approach_name,
                'X_test': X_test,
                'y_test': y_test,
                'y_pred_proba': y_pred_proba
            }
            
            print(f"    å‡†ç¡®ç‡: {accuracy:.4f}, AUC: {auc:.4f}")
        
        return results
    
    def compare_approaches(self, all_results):
        """æ¯”è¾ƒä¸åŒå»ºæ¨¡æ–¹æ³•çš„æ€§èƒ½"""
        print("\nğŸ“Š å»ºæ¨¡æ–¹æ³•æ€§èƒ½æ¯”è¾ƒ:")
        print("=" * 60)
        
        comparison_data = []
        for name, result in all_results.items():
            comparison_data.append({
                'Model': name,
                'Approach': result['approach'],
                'Accuracy': result['accuracy'],
                'AUC': result['auc']
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        comparison_df = comparison_df.sort_values('AUC', ascending=False)
        
        print(comparison_df.round(4))
        
        # ç»˜åˆ¶æ¯”è¾ƒå›¾
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # AUCæ¯”è¾ƒ
        ax1.barh(range(len(comparison_df)), comparison_df['AUC'])
        ax1.set_yticks(range(len(comparison_df)))
        ax1.set_yticklabels(comparison_df['Model'])
        ax1.set_xlabel('AUC Score')
        ax1.set_title('æ¨¡å‹AUCæ€§èƒ½æ¯”è¾ƒ')
        ax1.grid(True, alpha=0.3)
        
        # æŒ‰æ–¹æ³•åˆ†ç»„çš„AUCæ¯”è¾ƒ
        approach_auc = comparison_df.groupby('Approach')['AUC'].max()
        ax2.bar(range(len(approach_auc)), approach_auc.values)
        ax2.set_xticks(range(len(approach_auc)))
        ax2.set_xticklabels(approach_auc.index, rotation=45)
        ax2.set_ylabel('Best AUC Score')
        ax2.set_title('ä¸åŒå»ºæ¨¡æ–¹æ³•çš„æœ€ä½³AUC')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('longitudinal_model_comparison.png', dpi=300, bbox_inches='tight')
        print("\nğŸ“Š æ€§èƒ½æ¯”è¾ƒå›¾å·²ä¿å­˜: longitudinal_model_comparison.png")
        
        return comparison_df
    
    def save_best_longitudinal_model(self, all_results):
        """ä¿å­˜æœ€ä½³çºµå‘æ¨¡å‹"""
        best_result = max(all_results.items(), key=lambda x: x[1]['auc'])
        best_name, best_model_data = best_result
        
        print(f"\nğŸ’¾ ä¿å­˜æœ€ä½³çºµå‘æ¨¡å‹: {best_name}")
        print(f"AUC: {best_model_data['auc']:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(best_model_data['model'], 'best_longitudinal_cvd_model.pkl')
        joblib.dump(self.scaler, 'longitudinal_scaler.pkl')
        joblib.dump(self.imputer, 'longitudinal_imputer.pkl')
        
        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        model_info = {
            'model_name': best_name,
            'approach': best_model_data['approach'],
            'auc_score': best_model_data['auc'],
            'accuracy': best_model_data['accuracy']
        }
        
        import json
        with open('longitudinal_model_info.json', 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        
        return best_name, best_model_data

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ å¼—é›·æ˜æ±‰çºµå‘å¿ƒè¡€ç®¡ç–¾ç—…é£é™©é¢„æµ‹æ¨¡å‹")
    print("=" * 60)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = LongitudinalFraminghamPredictor()
    
    # åŠ è½½å’Œåˆ†ææ•°æ®
    df = predictor.load_and_analyze_data('../frmgham_data.csv')
    
    # åˆ›å»ºä¸åŒçš„å»ºæ¨¡æ–¹æ³•
    approaches = predictor.create_modeling_approaches(df)
    
    # è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ–¹æ³•
    all_results = {}
    
    for approach_name, approach_data in approaches.items():
        results = predictor.train_and_evaluate_approach(approach_name, approach_data)
        if results:
            all_results.update(results)
    
    # æ¯”è¾ƒä¸åŒæ–¹æ³•
    if all_results:
        comparison_df = predictor.compare_approaches(all_results)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        best_name, best_model = predictor.save_best_longitudinal_model(all_results)
        
        print("\nğŸ‰ çºµå‘å»ºæ¨¡å®Œæˆ!")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  - best_longitudinal_cvd_model.pkl (æœ€ä½³çºµå‘æ¨¡å‹)")
        print("  - longitudinal_scaler.pkl (æ ‡å‡†åŒ–å™¨)")
        print("  - longitudinal_imputer.pkl (ç¼ºå¤±å€¼å¤„ç†å™¨)")
        print("  - longitudinal_model_info.json (æ¨¡å‹ä¿¡æ¯)")
        print("  - longitudinal_model_comparison.png (æ€§èƒ½æ¯”è¾ƒå›¾)")
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_name}")
        print(f"ğŸ¯ AUCåˆ†æ•°: {best_model['auc']:.4f}")
    else:
        print("âŒ æ‰€æœ‰å»ºæ¨¡æ–¹æ³•éƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    main() 