#!/usr/bin/env python3
"""
å¼—é›·æ˜æ±‰çºµå‘å¿ƒè¡€ç®¡ç–¾ç—…é£é™©é¢„æµ‹æ¨¡å‹
æ­£ç¡®å¤„ç†æ¯ä¸ªæ‚£è€…çš„å¤šæ¬¡ä½“æ£€æ•°æ®
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score
import joblib
import warnings
warnings.filterwarnings('ignore')

np.random.seed(42)

def load_and_analyze_longitudinal_data(file_path):
    """åŠ è½½å’Œåˆ†æçºµå‘æ•°æ®"""
    print("ğŸ” åŠ è½½å¼—é›·æ˜æ±‰çºµå‘å¿ƒè„ç ”ç©¶æ•°æ®...")
    df = pd.read_csv(file_path)
    
    print(f"æ•°æ®åŸºæœ¬ä¿¡æ¯:")
    print(f"  æ€»è®°å½•æ•°: {len(df)}")
    print(f"  ç‹¬ç‰¹æ‚£è€…æ•°: {df['RANDID'].nunique()}")
    print(f"  CVDæ‚£ç—…ç‡: {(df['CVD']==1).mean():.3f}")
    
    # åˆ†æä½“æ£€æ¬¡æ•°åˆ†å¸ƒ
    visit_counts = df.groupby('RANDID').size()
    print(f"  ä½“æ£€æ¬¡æ•°åˆ†å¸ƒ:")
    for visits, count in visit_counts.value_counts().sort_index().items():
        print(f"    {visits}æ¬¡ä½“æ£€: {count}äºº")
    
    return df

def create_baseline_model(df):
    """åˆ›å»ºåŸºçº¿æ¨¡å‹ï¼šä½¿ç”¨ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®é¢„æµ‹CVDé£é™©"""
    print("\nğŸ“Š æ–¹æ³•1: åŸºçº¿é¢„æµ‹æ¨¡å‹ (ä½¿ç”¨ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®)")
    
    # è·å–ç¬¬ä¸€æ¬¡ä½“æ£€æ•°æ®
    baseline_data = df[df['PERIOD'] == 1].copy()
    
    # é€‰æ‹©é‡è¦ç‰¹å¾
    risk_factors = [
        'SEX', 'AGE', 'TOTCHOL', 'SYSBP', 'DIABP', 
        'CURSMOKE', 'CIGPDAY', 'BMI', 'DIABETES', 
        'BPMEDS', 'HEARTRTE', 'GLUCOSE', 'PREVCHD',
        'PREVAP', 'PREVMI', 'PREVSTRK', 'PREVHYP'
    ]
    
    available_features = [col for col in risk_factors if col in baseline_data.columns]
    X = baseline_data[available_features].copy()
    y = baseline_data['CVD']
    
    # ç‰¹å¾å·¥ç¨‹
    if 'SYSBP' in X.columns and 'DIABP' in X.columns:
        X['PULSE_PRESSURE'] = X['SYSBP'] - X['DIABP']
    
    if 'TOTCHOL' in X.columns and 'AGE' in X.columns:
        X['CHOL_AGE_RATIO'] = X['TOTCHOL'] / (X['AGE'] + 1)
    
    print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}, æ ·æœ¬æ•°é‡: {X.shape[0]}")
    print(f"CVDæ‚£ç—…ç‡: {y.mean():.3f}")
    
    return X, y, 'åŸºçº¿é¢„æµ‹æ¨¡å‹'

def create_longitudinal_model(df):
    """åˆ›å»ºçºµå‘æ¨¡å‹ï¼šåˆ©ç”¨å¤šæ¬¡ä½“æ£€çš„å˜åŒ–è¶‹åŠ¿"""
    print("\nğŸ“Š æ–¹æ³•2: çºµå‘å˜åŒ–æ¨¡å‹ (åˆ©ç”¨ä½“æ£€å˜åŒ–è¶‹åŠ¿)")
    
    longitudinal_features = []
    
    # è·å–æœ‰å¤šæ¬¡ä½“æ£€çš„æ‚£è€…
    multi_visit_patients = df.groupby('RANDID').size()
    multi_visit_patients = multi_visit_patients[multi_visit_patients >= 2].index
    
    for patient_id in multi_visit_patients:
        patient_data = df[df['RANDID'] == patient_id].sort_values('PERIOD')
        
        if len(patient_data) < 2:
            continue
            
        # åŸºçº¿æ•°æ®ï¼ˆç¬¬ä¸€æ¬¡ä½“æ£€ï¼‰
        baseline = patient_data.iloc[0]
        features = {}
        
        # åŸºçº¿ç‰¹å¾
        baseline_vars = ['SEX', 'AGE', 'DIABETES', 'PREVCHD', 'PREVMI', 'PREVSTRK']
        for var in baseline_vars:
            if var in baseline and pd.notna(baseline[var]):
                features[f'baseline_{var}'] = baseline[var]
        
        # è®¡ç®—å˜åŒ–è¶‹åŠ¿
        change_vars = ['TOTCHOL', 'SYSBP', 'DIABP', 'BMI', 'HEARTRTE', 'GLUCOSE']
        
        for var in change_vars:
            if var in patient_data.columns:
                values = patient_data[var].dropna()
                if len(values) >= 2:
                    # çº¿æ€§è¶‹åŠ¿
                    slope = np.polyfit(range(len(values)), values, 1)[0]
                    features[f'{var}_slope'] = slope
                    
                    # å˜åŒ–ç‡
                    first_val = values.iloc[0]
                    last_val = values.iloc[-1]
                    if first_val != 0:
                        features[f'{var}_change_rate'] = (last_val - first_val) / first_val
        
        # å¸çƒŸçŠ¶æ€å˜åŒ–
        if 'CURSMOKE' in patient_data.columns:
            smoke_values = patient_data['CURSMOKE'].dropna()
            if len(smoke_values) >= 2:
                features['smoking_change'] = smoke_values.iloc[-1] - smoke_values.iloc[0]
        
        # ç›®æ ‡å˜é‡
        features['CVD'] = baseline['CVD']
        longitudinal_features.append(features)
    
    # è½¬æ¢ä¸ºDataFrame
    long_df = pd.DataFrame(longitudinal_features)
    
    if len(long_df) == 0:
        return None, None, None
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
    feature_cols = [col for col in long_df.columns if col != 'CVD']
    X = long_df[feature_cols]
    y = long_df['CVD']
    
    print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}, æ ·æœ¬æ•°é‡: {X.shape[0]}")
    print(f"CVDæ‚£ç—…ç‡: {y.mean():.3f}")
    
    return X, y, 'çºµå‘å˜åŒ–æ¨¡å‹'

def train_and_evaluate_models(X, y, model_name):
    """è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹"""
    if X is None or y is None:
        print(f"âŒ {model_name}: æ•°æ®å‡†å¤‡å¤±è´¥")
        return {}
    
    print(f"\nğŸ¤– è®­ç»ƒ {model_name}...")
    
    # å¤„ç†ç¼ºå¤±å€¼
    imputer = SimpleImputer(strategy='median')
    X_imputed = imputer.fit_transform(X)
    X_imputed = pd.DataFrame(X_imputed, columns=X.columns)
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_imputed)
    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # å®šä¹‰æ¨¡å‹
    models = {
        'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),
        'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Gradient_Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
    }
    
    results = {}
    
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        
        accuracy = accuracy_score(y_test, model.predict(X_test))
        auc = roc_auc_score(y_test, y_pred_proba)
        
        results[f"{model_name}_{name}"] = {
            'model': model,
            'scaler': scaler,
            'imputer': imputer,
            'accuracy': accuracy,
            'auc': auc,
            'model_type': model_name
        }
        
        print(f"  {name}: å‡†ç¡®ç‡={accuracy:.4f}, AUC={auc:.4f}")
    
    return results

def compare_and_save_best_model(all_results):
    """æ¯”è¾ƒæ¨¡å‹æ€§èƒ½å¹¶ä¿å­˜æœ€ä½³æ¨¡å‹"""
    if not all_results:
        print("âŒ æ²¡æœ‰å¯æ¯”è¾ƒçš„æ¨¡å‹")
        return
    
    print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:")
    print("=" * 60)
    
    # åˆ›å»ºæ¯”è¾ƒè¡¨
    comparison_data = []
    for name, result in all_results.items():
        comparison_data.append({
            'Model': name,
            'Model_Type': result['model_type'],
            'Accuracy': result['accuracy'],
            'AUC': result['auc']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_df = comparison_df.sort_values('AUC', ascending=False)
    print(comparison_df.round(4).to_string(index=False))
    
    # æ‰¾åˆ°æœ€ä½³æ¨¡å‹
    best_model_name = comparison_df.iloc[0]['Model']
    best_result = all_results[best_model_name]
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}")
    print(f"ğŸ¯ AUCåˆ†æ•°: {best_result['auc']:.4f}")
    print(f"ğŸ“ˆ å‡†ç¡®ç‡: {best_result['accuracy']:.4f}")
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    joblib.dump(best_result['model'], 'best_longitudinal_model.pkl')
    joblib.dump(best_result['scaler'], 'longitudinal_scaler.pkl')
    joblib.dump(best_result['imputer'], 'longitudinal_imputer.pkl')
    
    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    model_info = {
        'model_name': best_model_name,
        'model_type': best_result['model_type'],
        'auc_score': best_result['auc'],
        'accuracy': best_result['accuracy']
    }
    
    import json
    with open('longitudinal_model_info.json', 'w', encoding='utf-8') as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    
    # ç»˜åˆ¶æ€§èƒ½æ¯”è¾ƒå›¾
    plt.figure(figsize=(12, 6))
    
    plt.subplot(1, 2, 1)
    plt.barh(range(len(comparison_df)), comparison_df['AUC'])
    plt.yticks(range(len(comparison_df)), comparison_df['Model'])
    plt.xlabel('AUC Score')
    plt.title('æ¨¡å‹AUCæ€§èƒ½æ¯”è¾ƒ')
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    model_types = comparison_df.groupby('Model_Type')['AUC'].max()
    plt.bar(range(len(model_types)), model_types.values)
    plt.xticks(range(len(model_types)), model_types.index, rotation=45)
    plt.ylabel('Best AUC Score')
    plt.title('ä¸åŒå»ºæ¨¡æ–¹æ³•çš„æœ€ä½³AUC')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('longitudinal_comparison.png', dpi=300, bbox_inches='tight')
    print("\nğŸ“Š æ€§èƒ½æ¯”è¾ƒå›¾å·²ä¿å­˜: longitudinal_comparison.png")
    
    return best_model_name, best_result

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ å¼—é›·æ˜æ±‰çºµå‘å¿ƒè¡€ç®¡ç–¾ç—…é£é™©é¢„æµ‹æ¨¡å‹")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    df = load_and_analyze_longitudinal_data('../frmgham_data.csv')
    
    # åˆ›å»ºä¸åŒå»ºæ¨¡æ–¹æ³•
    all_results = {}
    
    # æ–¹æ³•1: åŸºçº¿æ¨¡å‹
    X1, y1, name1 = create_baseline_model(df)
    results1 = train_and_evaluate_models(X1, y1, name1)
    all_results.update(results1)
    
    # æ–¹æ³•2: çºµå‘æ¨¡å‹
    X2, y2, name2 = create_longitudinal_model(df)
    results2 = train_and_evaluate_models(X2, y2, name2)
    all_results.update(results2)
    
    # æ¯”è¾ƒå’Œä¿å­˜æœ€ä½³æ¨¡å‹
    best_name, best_model = compare_and_save_best_model(all_results)
    
    print("\nğŸ‰ çºµå‘å»ºæ¨¡å®Œæˆ!")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - best_longitudinal_model.pkl (æœ€ä½³æ¨¡å‹)")
    print("  - longitudinal_scaler.pkl (æ ‡å‡†åŒ–å™¨)")
    print("  - longitudinal_imputer.pkl (ç¼ºå¤±å€¼å¤„ç†å™¨)")
    print("  - longitudinal_model_info.json (æ¨¡å‹ä¿¡æ¯)")
    print("  - longitudinal_comparison.png (æ€§èƒ½æ¯”è¾ƒå›¾)")
    
    print("\nğŸ’¡ æ•°æ®ç†è§£æ€»ç»“:")
    print("1. æ•°æ®åŒ…å«4434åæ‚£è€…ï¼Œæœ€å¤š3æ¬¡ä½“æ£€è®°å½•")
    print("2. CVD=1è¡¨ç¤ºåœ¨æ•´ä¸ªç ”ç©¶æœŸé—´æ›¾æ‚£å¿ƒè¡€ç®¡ç–¾ç—…")
    print("3. PREVCHD=1è¡¨ç¤ºåœ¨å½“å‰ä½“æ£€æ—¶å·²æ‚£å† å¿ƒç—…")
    print("4. TIMECVDè¡¨ç¤ºä»ç¬¬ä¸€æ¬¡ä½“æ£€åˆ°CVDè¯Šæ–­çš„æ—¶é—´(å°æ—¶)")
    print("5. åŸºçº¿æ¨¡å‹ä½¿ç”¨ç¬¬ä¸€æ¬¡ä½“æ£€é¢„æµ‹æœªæ¥CVDé£é™©")
    print("6. çºµå‘æ¨¡å‹åˆ©ç”¨å¤šæ¬¡ä½“æ£€çš„å˜åŒ–è¶‹åŠ¿")

if __name__ == "__main__":
    main() 