#!/usr/bin/env python3
"""
Coxæ—¶é—´å˜åŒ–ç”Ÿå­˜åˆ†ææ¨¡å‹è®­ç»ƒ
ä½¿ç”¨CoxTimeVaryingFitterå¤„ç†Framinghamçºµå‘æ•°æ®
"""

import pandas as pd
import numpy as np
import pickle
from lifelines import CoxTimeVaryingFitter
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import joblib
import warnings
warnings.filterwarnings('ignore')

def load_and_prepare_data(file_path='../frmgham_data.csv'):
    """åŠ è½½å¹¶å‡†å¤‡çºµå‘æ•°æ®"""
    print("ğŸ“Š åŠ è½½Framinghamçºµå‘æ•°æ®...")
    df = pd.read_csv(file_path)
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"ç‹¬ç‰¹æ‚£è€…æ•°: {df['RANDID'].nunique()}")
    print(f"PERIODåˆ†å¸ƒ:\n{df['PERIOD'].value_counts().sort_index()}")
    
    return df

def prepare_cox_tv_data(df):
    """å‡†å¤‡Coxæ—¶é—´å˜åŒ–æ¨¡å‹æ•°æ®"""
    print("ğŸ”„ å‡†å¤‡Coxæ—¶é—´å˜åŒ–æ•°æ®æ ¼å¼...")
    
    # æ ¸å¿ƒç‰¹å¾é€‰æ‹©
    features = [
        'SEX', 'AGE', 'TOTCHOL', 'SYSBP', 'DIABP', 'CURSMOKE', 
        'CIGPDAY', 'BMI', 'DIABETES', 'BPMEDS', 'HEARTRTE', 'GLUCOSE',
        'PREVCHD', 'PREVAP', 'PREVMI', 'PREVSTRK', 'PREVHYP'
    ]
    
    # åˆ›å»ºæ—¶é—´å˜åŒ–æ•°æ®æ ¼å¼
    tv_data = []
    
    for patient_id in df['RANDID'].unique():
        patient_data = df[df['RANDID'] == patient_id].sort_values('PERIOD')
        
        if len(patient_data) == 0:
            continue
            
        # è·å–æ‚£è€…çš„æœ€ç»ˆçŠ¶æ€
        max_time = patient_data['TIME'].max()
        final_cvd = patient_data['CVD'].iloc[-1]
        
        # ä¸ºæ¯ä¸ªPERIODåˆ›å»ºè®°å½•
        for i, (_, row) in enumerate(patient_data.iterrows()):
            # è®¡ç®—æ—¶é—´åŒºé—´
            start_time = 0 if i == 0 else patient_data.iloc[i-1]['TIME']
            stop_time = row['TIME']
            
            # ä¿®å¤æ—¶é—´é—´éš”ä¸º0çš„é—®é¢˜
            if start_time == stop_time:
                stop_time = start_time + 0.5  # æ·»åŠ æœ€å°æ—¶é—´é—´éš”
            
            # äº‹ä»¶åªåœ¨æœ€åä¸€ä¸ªè®°å½•ä¸­å‘ç”Ÿ
            event = final_cvd if i == len(patient_data) - 1 else 0
            
            # æ„å»ºè®°å½•
            record = {
                'id': patient_id,
                'start': start_time,
                'stop': stop_time,
                'event': event
            }
            
            # æ·»åŠ ç‰¹å¾
            for feature in features:
                if feature in row and pd.notna(row[feature]):
                    record[feature] = row[feature]
                else:
                    # ä½¿ç”¨é»˜è®¤å€¼
                    defaults = {
                        'SEX': 1, 'AGE': 50, 'TOTCHOL': 200, 'SYSBP': 120, 'DIABP': 80,
                        'CURSMOKE': 0, 'CIGPDAY': 0, 'BMI': 25, 'DIABETES': 0,
                        'BPMEDS': 0, 'HEARTRTE': 70, 'GLUCOSE': 90,
                        'PREVCHD': 0, 'PREVAP': 0, 'PREVMI': 0, 'PREVSTRK': 0, 'PREVHYP': 0
                    }
                    record[feature] = defaults.get(feature, 0)
            
            tv_data.append(record)
    
    tv_df = pd.DataFrame(tv_data)
    print(f"æ—¶é—´å˜åŒ–æ•°æ®å½¢çŠ¶: {tv_df.shape}")
    print(f"äº‹ä»¶æ•°é‡: {tv_df['event'].sum()}")
    
    return tv_df, features

def train_cox_tv_model(tv_df, features):
    """è®­ç»ƒCoxæ—¶é—´å˜åŒ–æ¨¡å‹"""
    print("ğŸ§  è®­ç»ƒCoxæ—¶é—´å˜åŒ–æ¨¡å‹...")
    
    # æ•°æ®é¢„å¤„ç†
    print("ğŸ“‹ æ•°æ®é¢„å¤„ç†...")
    
    # å¡«å……ç¼ºå¤±å€¼
    imputer = SimpleImputer(strategy='median')
    tv_df[features] = imputer.fit_transform(tv_df[features])
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    tv_df[features] = scaler.fit_transform(tv_df[features])
    
    # è®­ç»ƒCoxæ—¶é—´å˜åŒ–æ¨¡å‹
    print("ğŸ”¬ è®­ç»ƒæ¨¡å‹...")
    ctv = CoxTimeVaryingFitter()
    
    try:
        ctv.fit(tv_df, 
                id_col='id', 
                start_col='start', 
                stop_col='stop', 
                event_col='event',
                show_progress=True)
        
        print("âœ… Coxæ—¶é—´å˜åŒ–æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")
        
        # æ˜¾ç¤ºæ¨¡å‹æ‘˜è¦
        print("\nğŸ“Š æ¨¡å‹æ‘˜è¦:")
        print(ctv.summary.head(10))
        
        # æ˜¾ç¤ºä¸€è‡´æ€§æŒ‡æ•° (CoxTimeVaryingFitterç”¨ä¸åŒçš„å±æ€§å)
        try:
            c_index = ctv.concordance_index_
            print(f"\nğŸ¯ ä¸€è‡´æ€§æŒ‡æ•° (C-index): {c_index:.4f}")
        except AttributeError:
            print("\nğŸ¯ æ¨¡å‹è®­ç»ƒæˆåŠŸï¼ŒC-indexå°†åœ¨è¯„ä¼°é˜¶æ®µè®¡ç®—")
        
        return ctv, scaler, imputer, tv_df
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        return None, None, None, None

def save_models(ctv, scaler, imputer, features):
    """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
    
    try:
        # ä¿å­˜Coxæ¨¡å‹
        with open('cox_timevarying_model.pkl', 'wb') as f:
            pickle.dump(ctv, f)
        
        # ä¿å­˜é¢„å¤„ç†å™¨
        joblib.dump(scaler, 'cox_tv_scaler.pkl')
        joblib.dump(imputer, 'cox_tv_imputer.pkl')
        
        # ä¿å­˜ç‰¹å¾åç§°
        with open('cox_tv_features.pkl', 'wb') as f:
            pickle.dump(features, f)
        
        print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸï¼")
        print("ğŸ“ ä¿å­˜çš„æ–‡ä»¶:")
        print("  - cox_timevarying_model.pkl")
        print("  - cox_tv_scaler.pkl") 
        print("  - cox_tv_imputer.pkl")
        print("  - cox_tv_features.pkl")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")

def evaluate_model(ctv, tv_df):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°:")
    
    try:
        # ä¸€è‡´æ€§æŒ‡æ•° (å¯¹äºCoxTimeVaryingFitteréœ€è¦æ‰‹åŠ¨è®¡ç®—)
        try:
            c_index = ctv.concordance_index_
        except AttributeError:
            # å¦‚æœæ²¡æœ‰concordance_index_å±æ€§ï¼Œä½¿ç”¨Noneæˆ–è·³è¿‡
            c_index = None
            print("C-index: å°†åœ¨å®é™…é¢„æµ‹ä¸­è¯„ä¼°")
        
        if c_index is not None:
            print(f"C-index: {c_index:.4f}")
        
        # é£é™©æ¯”åˆ†æ
        hazard_ratios = ctv.hazard_ratios_
        print("\nğŸ” ä¸»è¦é£é™©å› å­ (å‰10ä¸ª):")
        top_hr = hazard_ratios.abs().sort_values(ascending=False).head(10)
        for feature, hr in top_hr.items():
            direction = "â†‘" if hazard_ratios[feature] > 1 else "â†“"
            print(f"  {feature}: HR={hazard_ratios[feature]:.3f} {direction}")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        evaluation = {
            'c_index': float(c_index) if c_index is not None else None,
            'n_events': int(tv_df['event'].sum()),
            'n_observations': len(tv_df),
            'n_patients': tv_df['id'].nunique(),
            'hazard_ratios': hazard_ratios.to_dict()
        }
        
        with open('cox_tv_evaluation.pkl', 'wb') as f:
            pickle.dump(evaluation, f)
        
        print("ğŸ“Š è¯„ä¼°ç»“æœå·²ä¿å­˜: cox_tv_evaluation.pkl")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ Coxæ—¶é—´å˜åŒ–ç”Ÿå­˜åˆ†ææ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # 1. åŠ è½½æ•°æ®
    df = load_and_prepare_data()
    
    # 2. å‡†å¤‡æ—¶é—´å˜åŒ–æ•°æ®
    tv_df, features = prepare_cox_tv_data(df)
    
    if tv_df is None or len(tv_df) == 0:
        print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥")
        return
    
    # 3. è®­ç»ƒæ¨¡å‹
    ctv, scaler, imputer, processed_tv_df = train_cox_tv_model(tv_df, features)
    
    if ctv is None:
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return
    
    # 4. è¯„ä¼°æ¨¡å‹
    evaluate_model(ctv, processed_tv_df)
    
    # 5. ä¿å­˜æ¨¡å‹
    save_models(ctv, scaler, imputer, features)
    
    print("\nğŸ‰ Coxæ—¶é—´å˜åŒ–æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("ğŸš€ ç°åœ¨å¯ä»¥éƒ¨ç½²æ–°çš„ç”Ÿå­˜åˆ†æç³»ç»Ÿäº†ï¼")

if __name__ == "__main__":
    main() 